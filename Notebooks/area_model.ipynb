{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from PIL import Image\n",
    "import tifffile as tiff\n",
    "from tensorflow.keras.utils import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TARGET = os.environ.get('MODEL_TARGET')\n",
    "GCP_PROJECT = os.environ.get('GCP_PROJECT')\n",
    "GCP_REGION = os.environ.get('GCP_REGION')\n",
    "\n",
    "BUCKET_NAME = os.environ.get('BUCKET_NAME')\n",
    "BQ_REGION = os.environ.get('BQ_REGION')\n",
    "BQ_DATASET = os.environ.get('BQ_DATASET')\n",
    "PLATE_NUMBER = os.environ.get('PLATE_NUMBER')\n",
    "\n",
    "LOCAL_DATA_PATH = os.path.join(os.path.expanduser('~'), \".morpho_minds_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2304 entries, 0 to 2303\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PhGolgi      2304 non-null   object \n",
      " 1   Hoechst      2304 non-null   object \n",
      " 2   ERSyto       2304 non-null   object \n",
      " 3   Mito         2304 non-null   object \n",
      " 4   ERSytoBleed  2304 non-null   object \n",
      " 5   CellCount    2304 non-null   int64  \n",
      " 6   Well         2304 non-null   object \n",
      " 7   PhotoNumber  2304 non-null   int64  \n",
      " 8   Role         2304 non-null   object \n",
      " 9   MMoles       2304 non-null   float64\n",
      " 10  Plate        2304 non-null   int64  \n",
      " 11  MeanArea     2304 non-null   float64\n",
      "dtypes: float64(2), int64(3), object(7)\n",
      "memory usage: 216.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(os.path.join(LOCAL_DATA_PATH, PLATE_NUMBER, 'processed', f'{PLATE_NUMBER}_small.csv'))\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_df = data_df['PhGolgi'].map(lambda x: str(Path(LOCAL_DATA_PATH).joinpath(PLATE_NUMBER, 'raw', 'pictures', f'{PLATE_NUMBER}-Ph_golgi', x.split('/')[-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_image_files = {'channel' : []}\n",
    "channel_images = {'channel' : []}\n",
    "\n",
    "for path in paths_df:\n",
    "\n",
    "    channel_image_files['channel'].append(path)\n",
    "\n",
    "    img = load_img(paths_df[0], target_size=(224, 224), color_mode='grayscale')\n",
    "    img_array = img_to_array(img)\n",
    "    img_array_expanded = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    channel_images['channel'].append(img_array_expanded)\n",
    "\n",
    "images_batch = np.vstack(channel_images['channel'])\n",
    "images_batch/=65535"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images_batch, data_df['CellCount'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "771.4876030815972"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model_score = np.sum((data_df['CellCount'] - data_df['CellCount'].mean())**2)/data_df.shape[0]\n",
    "base_model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(16, kernel_size=(4,4), activation = 'relu', input_shape = (224,224,1)))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, kernel_size=(3,3), activation = 'relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(64, kernel_size=(2,2), activation = 'relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(layers.Conv2D(32, kernel_size=(2,2), activation = 'relu'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(10, activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/41 [==============================] - 25s 592ms/step - loss: 6502.0098 - val_loss: 839.2781\n",
      "Epoch 2/100\n",
      "41/41 [==============================] - 24s 591ms/step - loss: 848.7863 - val_loss: 743.9148\n",
      "Epoch 3/100\n",
      "41/41 [==============================] - 25s 615ms/step - loss: 799.6616 - val_loss: 742.4132\n",
      "Epoch 4/100\n",
      "41/41 [==============================] - 24s 579ms/step - loss: 796.3509 - val_loss: 756.0438\n",
      "Epoch 5/100\n",
      "41/41 [==============================] - 23s 572ms/step - loss: 815.2994 - val_loss: 738.8386\n",
      "Epoch 6/100\n",
      "41/41 [==============================] - 24s 597ms/step - loss: 806.3151 - val_loss: 794.6522\n",
      "Epoch 7/100\n",
      "41/41 [==============================] - 23s 574ms/step - loss: 822.7060 - val_loss: 739.1923\n",
      "Epoch 8/100\n",
      "41/41 [==============================] - 23s 571ms/step - loss: 812.3753 - val_loss: 786.9669\n",
      "Epoch 9/100\n",
      "41/41 [==============================] - 23s 567ms/step - loss: 808.0828 - val_loss: 745.9781\n",
      "Epoch 10/100\n",
      "41/41 [==============================] - 23s 566ms/step - loss: 828.7213 - val_loss: 864.3330\n",
      "Epoch 11/100\n",
      "41/41 [==============================] - 23s 571ms/step - loss: 863.6540 - val_loss: 738.9521\n",
      "Epoch 12/100\n",
      "41/41 [==============================] - 24s 598ms/step - loss: 813.7846 - val_loss: 742.0956\n",
      "Epoch 13/100\n",
      "41/41 [==============================] - 54s 1s/step - loss: 807.8784 - val_loss: 760.0439\n",
      "Epoch 14/100\n",
      "41/41 [==============================] - 30s 734ms/step - loss: 804.9835 - val_loss: 742.9626\n",
      "Epoch 15/100\n",
      "41/41 [==============================] - 31s 764ms/step - loss: 830.9421 - val_loss: 795.4055\n",
      "Epoch 16/100\n",
      "41/41 [==============================] - 28s 696ms/step - loss: 819.1005 - val_loss: 750.9505\n",
      "Epoch 17/100\n",
      "41/41 [==============================] - 29s 696ms/step - loss: 796.1008 - val_loss: 749.2366\n",
      "Epoch 18/100\n",
      "41/41 [==============================] - 28s 671ms/step - loss: 815.7673 - val_loss: 739.4603\n",
      "Epoch 19/100\n",
      "41/41 [==============================] - 28s 685ms/step - loss: 824.8542 - val_loss: 741.4925\n",
      "Epoch 20/100\n",
      "41/41 [==============================] - 28s 683ms/step - loss: 819.8887 - val_loss: 748.4001\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model()\n",
    "es = EarlyStopping(patience = 15, restore_best_weights = True)\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_split = 0.3,\n",
    "                    batch_size = 32,\n",
    "                    epochs = 100,\n",
    "                    callbacks = [es],\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 2s 115ms/step - loss: 759.3409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "759.3409423828125"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 0 classes.\n",
      "Using 0 files for training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory /Users/pepe/.morpho_minds_data/24585/raw/pictures/24585-Ph_golgi/. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [30], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m img_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m180\u001b[39m\n\u001b[1;32m      4\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(LOCAL_DATA_PATH, PLATE_NUMBER, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpictures\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPLATE_NUMBER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-Ph_golgi/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimg_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/MorphoMind/lib/python3.10/site-packages/keras/utils/image_dataset.py:294\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m image_paths, labels \u001b[38;5;241m=\u001b[39m dataset_utils\u001b[38;5;241m.\u001b[39mget_training_or_validation_split(\n\u001b[1;32m    291\u001b[0m     image_paths, labels, validation_split, subset\n\u001b[1;32m    292\u001b[0m )\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_paths:\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo images found in directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    296\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAllowed formats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWLIST_FORMATS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    299\u001b[0m dataset \u001b[38;5;241m=\u001b[39m paths_and_labels_to_dataset(\n\u001b[1;32m    300\u001b[0m     image_paths\u001b[38;5;241m=\u001b[39mimage_paths,\n\u001b[1;32m    301\u001b[0m     image_size\u001b[38;5;241m=\u001b[39mimage_size,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    307\u001b[0m     crop_to_aspect_ratio\u001b[38;5;241m=\u001b[39mcrop_to_aspect_ratio,\n\u001b[1;32m    308\u001b[0m )\n\u001b[1;32m    309\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n",
      "\u001b[0;31mValueError\u001b[0m: No images found in directory /Users/pepe/.morpho_minds_data/24585/raw/pictures/24585-Ph_golgi/. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "data_dir = os.path.join(LOCAL_DATA_PATH, PLATE_NUMBER, 'raw', 'pictures', f'{PLATE_NUMBER}-Ph_golgi')\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MorphoMind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
